{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d1c6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114d1e6",
   "metadata": {},
   "source": [
    "# Task 1: Cleaning the dataframe\n",
    "##### - Create column 'avaliacoes'\n",
    "##### - Drop NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e4c8374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estou muito satisfeito, o visor é melhor do qu...</td>\n",
       "      <td>4</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"muito boa\\n\\nO que gostei: preco\\n\\nO que não...</td>\n",
       "      <td>5</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rápida, ótima qualidade de impressão e fácil d...</td>\n",
       "      <td>5</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Produto de ótima qualidade em todos os quesito!</td>\n",
       "      <td>5</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precisava comprar uma tv compatível com meu dv...</td>\n",
       "      <td>5</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating sentiment\n",
       "0  Estou muito satisfeito, o visor é melhor do qu...       4  positivo\n",
       "1  \"muito boa\\n\\nO que gostei: preco\\n\\nO que não...       5  positivo\n",
       "2  Rápida, ótima qualidade de impressão e fácil d...       5  positivo\n",
       "3    Produto de ótima qualidade em todos os quesito!       5  positivo\n",
       "4  Precisava comprar uma tv compatível com meu dv...       5  positivo"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(rating):\n",
    "    if rating < 3:\n",
    "        return 'negativo'\n",
    "    elif rating == 3:\n",
    "        return 'neutro'\n",
    "    elif rating > 3:\n",
    "        return 'positivo'\n",
    "\n",
    "df = pd.read_csv('./dataset/avaliacoes.csv')\n",
    "df['sentiment'] = df.rating.apply(lambda rating : get_sentiment(rating))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ec70995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop NA:\n",
      "review_text    84990\n",
      "rating         84991\n",
      "sentiment      84991\n",
      "dtype: int64\n",
      "----------\n",
      "After drop NA:\n",
      "review_text    84990\n",
      "rating         84990\n",
      "sentiment      84990\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Before drop NA:')\n",
    "print(df.count())\n",
    "#there is 1 missing value at 'review_text'\n",
    "df.dropna(inplace=True)\n",
    "print('-'*10)\n",
    "print('After drop NA:')\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf194f",
   "metadata": {},
   "source": [
    "### Subtask 2: Evenly distributed dataframe\n",
    "##### - Same quantity of positive, negative and neutral reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cd5d10c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63854</th>\n",
       "      <td>Pense num arrependimento, samsung nunca mais. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>NÃO SEI O QUE MAIS GOSTO, POIS TIREI-O DA CAIX...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49371</th>\n",
       "      <td>TENHO UM REFRIGERADOR SEXTO SENTIDO PAGUEI r$ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64356</th>\n",
       "      <td>Aparentemente um produto muito bom, abrange as...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>Um produto com pouca Qualidade, mas ideal pra ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  rating sentiment\n",
       "63854  Pense num arrependimento, samsung nunca mais. ...       2  negativo\n",
       "2889   NÃO SEI O QUE MAIS GOSTO, POIS TIREI-O DA CAIX...       2  negativo\n",
       "49371  TENHO UM REFRIGERADOR SEXTO SENTIDO PAGUEI r$ ...       1  negativo\n",
       "64356  Aparentemente um produto muito bom, abrange as...       1  negativo\n",
       "11507  Um produto com pouca Qualidade, mas ideal pra ...       2  negativo"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evenly_distrubute_quantity = df[df.sentiment == 'neutro'].count()[0]\n",
    "\n",
    "evenly_distrubute_quantity\n",
    "df_1 = df.groupby('sentiment', as_index=False, group_keys=False).apply(lambda x: x.sample(n=evenly_distrubute_quantity, random_state=1, replace=True))\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29036331",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Subtask 3: Review text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4714f2d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63854</th>\n",
       "      <td>pense num arrependimento, samsung nunca mais. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>não sei o que mais gosto, pois tirei-o da caix...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49371</th>\n",
       "      <td>tenho um refrigerador sexto sentido paguei r$ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64356</th>\n",
       "      <td>aparentemente um produto muito bom, abrange as...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>um produto com pouca qualidade, mas ideal pra ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  rating sentiment\n",
       "63854  pense num arrependimento, samsung nunca mais. ...       2  negativo\n",
       "2889   não sei o que mais gosto, pois tirei-o da caix...       2  negativo\n",
       "49371  tenho um refrigerador sexto sentido paguei r$ ...       1  negativo\n",
       "64356  aparentemente um produto muito bom, abrange as...       1  negativo\n",
       "11507  um produto com pouca qualidade, mas ideal pra ...       2  negativo"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['review_text'] = df_1['review_text'].str.lower()\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d9548",
   "metadata": {},
   "source": [
    "# Task 2: Stopwords removal and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7842f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\iago1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\iago1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b0e1b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "def get_tokenized(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a593cfc3",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "##### stopwords are words that we want to ignore because they dont altere the meaning of the phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "af4fba9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('portuguese')\n",
    "\n",
    "stop_words.remove('não')\n",
    "# the word 'não' is very important to us\n",
    "\n",
    "def get_text_stopworded(text):\n",
    "    text_tokenized = get_tokenized(text)\n",
    "    \n",
    "    text_stopworded = []\n",
    "    \n",
    "    for word in text_tokenized:\n",
    "        if word not in stop_words:\n",
    "            text_stopworded.append(word)\n",
    "    \n",
    "    text_stopworded = (\" \").join(text_stopworded)\n",
    "    \n",
    "    return text_stopworded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff00c90",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "##### Stemming is the process of reducing inflected words. For example, the words \"likes\" and \"liked\" will be transformed into 'like\" and our program will consider as the same meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "16496722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_stemmed(text):\n",
    "    text_tokenized = get_tokenized(text)\n",
    "    \n",
    "    text_stemmed = []\n",
    "    stemmer = RSLPStemmer()\n",
    "\n",
    "    for word in text_tokenized:\n",
    "        word_stemmed = stemmer.stem(word)\n",
    "        text_stemmed.append(word_stemmed)\n",
    "    \n",
    "    text_stemmed = (\" \").join(text_stemmed)\n",
    "    \n",
    "    return text_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4fc5d",
   "metadata": {},
   "source": [
    "### Getting the stopworded, stemmed and stopworded/stemmed columns to compare the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "68aab7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_text_stopworded</th>\n",
       "      <th>review_text_stemmed</th>\n",
       "      <th>review_text_stopworded_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63854</th>\n",
       "      <td>pense num arrependimento, samsung nunca mais. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "      <td>pense arrependimento , samsung nunca . querem ...</td>\n",
       "      <td>pens num arrepend , samsung nunc mais . quer c...</td>\n",
       "      <td>pens arrepend , samsung nunc . quer celul bom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>não sei o que mais gosto, pois tirei-o da caix...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "      <td>não sei gosto , pois tirei-o caixa não funcion...</td>\n",
       "      <td>não sei o que mais gost , poi tirei- da caix e...</td>\n",
       "      <td>não sei gost , poi tirei- caix não func aquec ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49371</th>\n",
       "      <td>tenho um refrigerador sexto sentido paguei r$ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "      <td>refrigerador sexto sentido paguei r $ 3.500,00...</td>\n",
       "      <td>tenh um refriger sext sent pag r $ 3.500,00 e ...</td>\n",
       "      <td>refriger sext sent pag r $ 3.500,00 deu defeit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64356</th>\n",
       "      <td>aparentemente um produto muito bom, abrange as...</td>\n",
       "      <td>1</td>\n",
       "      <td>negativo</td>\n",
       "      <td>aparentemente produto bom , abrange principais...</td>\n",
       "      <td>aparent um produt muit bom , abrang as princip...</td>\n",
       "      <td>aparent produt bom , abrang princip falh máqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11507</th>\n",
       "      <td>um produto com pouca qualidade, mas ideal pra ...</td>\n",
       "      <td>2</td>\n",
       "      <td>negativo</td>\n",
       "      <td>produto pouca qualidade , ideal pra poucos rec...</td>\n",
       "      <td>um produt com pouc qual , mas ideal pra qu tem...</td>\n",
       "      <td>produt pouc qual , ideal pra pouc recurs porqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  rating sentiment  \\\n",
       "63854  pense num arrependimento, samsung nunca mais. ...       2  negativo   \n",
       "2889   não sei o que mais gosto, pois tirei-o da caix...       2  negativo   \n",
       "49371  tenho um refrigerador sexto sentido paguei r$ ...       1  negativo   \n",
       "64356  aparentemente um produto muito bom, abrange as...       1  negativo   \n",
       "11507  um produto com pouca qualidade, mas ideal pra ...       2  negativo   \n",
       "\n",
       "                                  review_text_stopworded  \\\n",
       "63854  pense arrependimento , samsung nunca . querem ...   \n",
       "2889   não sei gosto , pois tirei-o caixa não funcion...   \n",
       "49371  refrigerador sexto sentido paguei r $ 3.500,00...   \n",
       "64356  aparentemente produto bom , abrange principais...   \n",
       "11507  produto pouca qualidade , ideal pra poucos rec...   \n",
       "\n",
       "                                     review_text_stemmed  \\\n",
       "63854  pens num arrepend , samsung nunc mais . quer c...   \n",
       "2889   não sei o que mais gost , poi tirei- da caix e...   \n",
       "49371  tenh um refriger sext sent pag r $ 3.500,00 e ...   \n",
       "64356  aparent um produt muit bom , abrang as princip...   \n",
       "11507  um produt com pouc qual , mas ideal pra qu tem...   \n",
       "\n",
       "                          review_text_stopworded_stemmed  \n",
       "63854  pens arrepend , samsung nunc . quer celul bom ...  \n",
       "2889   não sei gost , poi tirei- caix não func aquec ...  \n",
       "49371  refriger sext sent pag r $ 3.500,00 deu defeit...  \n",
       "64356  aparent produt bom , abrang princip falh máqui...  \n",
       "11507  produt pouc qual , ideal pra pouc recurs porqu...  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2['review_text_stopworded'] = df_2['review_text'].apply(lambda rev: get_text_stopworded(rev))\n",
    "df_2['review_text_stemmed'] = df_2['review_text'].apply(lambda rev: get_text_stemmed(rev))\n",
    "df_2['review_text_stopworded_stemmed'] = df_2['review_text_stopworded'].apply(lambda rev: get_text_stemmed(rev))\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb5771",
   "metadata": {},
   "source": [
    "#### Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7792e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('./dataset/avaliacao_limpa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5ac1f",
   "metadata": {},
   "source": [
    "# Task 3: Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3f0f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_2 = pd.read_csv('./dataset/avaliacao_limpa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6916e1f",
   "metadata": {},
   "source": [
    "### Separating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17348d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_2['sentiment']\n",
    "\n",
    "X = df_2['review_text']\n",
    "X_stopworded = df_2['review_text_stopworded']\n",
    "X_stemmed = df_2['review_text_stemmed']\n",
    "X_stopworded_stemmed = df_2['review_text_stopworded_stemmed']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_stopworded, X_test_stopworded, y_train, y_test = train_test_split(X_stopworded, y, test_size=0.2, random_state=42)\n",
    "X_train_stemmed, X_test_stemmed, y_train, y_test = train_test_split(X_stemmed, y, test_size=0.2, random_state=42)\n",
    "X_train_stopworded_stemmed, X_test_stopworded_stemmed, y_train, y_test = train_test_split(X_stopworded_stemmed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b95467",
   "metadata": {},
   "source": [
    "### Vectorizing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40294e0",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f879b994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32236"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "# Quantity of words we have\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230588f",
   "metadata": {},
   "source": [
    "##### Without data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de5b86cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iago1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "# Quantity of words we have\n",
    "len(vectorizer.get_feature_names())\n",
    "\n",
    "clf_log = LogisticRegression(max_iter=300)\n",
    "clf_log.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f5228c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7724006452559026"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "clf_log.score(X_test_vectors, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d010295f",
   "metadata": {},
   "source": [
    "##### Stopworded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "adf20848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iago1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_sw = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_stopworded_vectors = vectorizer_sw.fit_transform(X_train_stopworded.values.astype('U'))\n",
    "\n",
    "clf_log_sw = LogisticRegression(max_iter=300)\n",
    "clf_log_sw.fit(X_train_stopworded_vectors, y_train_stopworded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6df85fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652148408857604"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stopworded_vectors = vectorizer_sw.transform(X_test_stopworded.values.astype('U'))\n",
    "clf_log_sw.score(X_test_stopworded_vectors, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c75a6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542161607273794"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stopworded_vectors = vectorizer.transform(X_test_stopworded.values.astype('U'))\n",
    "clf_log.score(X_test_stopworded_vectors, y_test)x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34f2ec",
   "metadata": {},
   "source": [
    "##### Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "479de655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iago1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_st = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_stemmed_vectors = vectorizer_st.fit_transform(X_train_stemmed)\n",
    "\n",
    "clf_log_st = LogisticRegression(max_iter=300)\n",
    "clf_log_st.fit(X_train_stemmed_vectors, y_train_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f78ed92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738084763161754"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stemmed_vectors = vectorizer_st.transform(X_test_stemmed)\n",
    "clf_log_st.score(X_test_stemmed_vectors, y_test_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211109c",
   "metadata": {},
   "source": [
    "##### Stopworded & Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebbfd716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iago1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_sw_st = CountVectorizer(binary=True)\n",
    "\n",
    "X_train_stopworded_stemmed_vectors = vectorizer_sw_st.fit_transform(X_train_stopworded_stemmed.values.astype('U'))\n",
    "\n",
    "clf_log_sw_st = LogisticRegression(max_iter=300)\n",
    "clf_log_sw_st.fit(X_train_stopworded_stemmed_vectors, y_train_stopworded_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "899d233f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7344185364422936"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stopworded_stemmed_vectors = vectorizer_sw_st.transform(X_test_stopworded_stemmed.values.astype('U'))\n",
    "\n",
    "clf_log_sw_st.score(X_test_stopworded_stemmed_vectors, y_test_stopworded_stemmed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
